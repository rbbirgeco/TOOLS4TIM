# Neural Coding Assistant - Signal Flow Architecture

```mermaid
graph TD
    %% External Interfaces
    User[ğŸ‘¤ User/Developer] --> API[ğŸŒ REST API<br/>FastAPI Server<br/>:8000]
    IDE[ğŸ› ï¸ VS Code<br/>Continue Extension] --> API
    CLI[ğŸ’» Command Line<br/>Interface] --> API
    
    %% API Layer
    API --> Health[â¤ï¸ /health]
    API --> Models[ğŸ“‹ /models]
    API --> Chat[ğŸ’¬ /v1/chat/completions]
    
    %% Main Processing Flow
    Chat --> ErrorHandler{ğŸ›¡ï¸ Error Handler<br/>- Validation<br/>- Timeout<br/>- Retry Logic}
    ErrorHandler --> Dispatcher[ğŸ¯ Admin Dispatcher<br/>admin_dispatcher.py]
    
    %% Administrative Mesh Processing
    Dispatcher --> TaskParser[ğŸ“ Task Parser<br/>Enhanced Classification]
    TaskParser --> Config[âš™ï¸ Config System<br/>config.py]
    Config --> Keywords{ğŸ” Keyword Analysis<br/>- debug: error, bug<br/>- analyze: review, inspect<br/>- fix: repair, solve<br/>- clean: optimize<br/>- refactor: restructure}
    
    TaskParser --> CouncilRouter[ğŸ›ï¸ Council Router<br/>Model Selection]
    CouncilRouter --> AdminModel[ğŸ¤– Selected Admin Model]
    
    Dispatcher --> AttentionRouter[ğŸ¯ Attention Router<br/>Context Retrieval]
    AttentionRouter --> AgentMemory[(ğŸ§  Agent Memory<br/>JSON Files)]
    
    Dispatcher --> MemoryExpander[ğŸ“ˆ Memory Expander<br/>Context Compression]
    
    Dispatcher --> FunctionCourier[ğŸ“‹ Function Courier<br/>Signature Parser]
    FunctionCourier --> Config
    FunctionCourier --> CourierMD[ğŸ“„ Function_Courier.md<br/>Fallback Signatures]
    
    %% Payload Assembly
    Dispatcher --> PayloadAssembly[ğŸ“¦ Payload Assembly<br/>- code_str<br/>- error_msg<br/>- context<br/>- function_sig]
    
    %% LLM Mesh Processing
    PayloadAssembly --> MeshManager[ğŸ•¸ï¸ Mesh Manager<br/>mesh_manager.py]
    
    MeshManager --> TaskRouter{ğŸ”€ Task Router<br/>Route by Type}
    
    %% Worker Handlers
    TaskRouter -->|debug| DebugHandler[ğŸ› Debug Handler<br/>_handle_debug_task]
    TaskRouter -->|analyze| AnalyzeHandler[ğŸ” Analyze Handler<br/>_handle_analyze_task]
    TaskRouter -->|fix| FixHandler[ğŸ”§ Fix Handler<br/>_handle_fix_task]
    TaskRouter -->|clean| CleanHandler[ğŸ§¹ Clean Handler<br/>_handle_clean_task]
    TaskRouter -->|refactor| RefactorHandler[ğŸ”„ Refactor Handler<br/>_handle_refactor_task]
    
    %% Worker Implementation Layers
    DebugHandler --> WolframDebug[ğŸ§® Wolfram Worker<br/>Subprocess Call]
    AnalyzeHandler --> WolframAnalyze[ğŸ§® Wolfram Worker<br/>Subprocess Call]
    FixHandler --> PytorchFix[ğŸ”¥ PyTorch Model<br/>In-Process]
    CleanHandler --> WolframClean[ğŸ§® Wolfram Worker<br/>Subprocess Call]
    RefactorHandler --> LocalRefactor[ğŸ  Local Handler<br/>Fallback Logic]
    
    %% Fallback System
    WolframDebug --> FallbackCheck{â“ Wolfram Available?}
    WolframAnalyze --> FallbackCheck
    WolframClean --> FallbackCheck
    
    FallbackCheck -->|No| MockDebug[ğŸ”„ Fallback Debug<br/>Mock Response]
    FallbackCheck -->|No| MockAnalyze[ğŸ”„ Fallback Analyze<br/>Mock Response]
    FallbackCheck -->|No| MockClean[ğŸ”„ Fallback Clean<br/>Mock Response]
    
    FallbackCheck -->|Yes| WolframExec[âš¡ Wolfram Execution<br/>asyncio subprocess]
    
    %% PyTorch Path
    PytorchFix --> ModelCheck{ğŸ¤– Model Available?}
    ModelCheck -->|No| MockFix[ğŸ”„ Fallback Fix<br/>Mock Response]
    ModelCheck -->|Yes| LlamaModel[ğŸ¦™ llama-cpp-python<br/>GGUF Models]
    
    %% Results Aggregation
    WolframExec --> ResultAgg[ğŸ“Š Result Aggregation]
    MockDebug --> ResultAgg
    MockAnalyze --> ResultAgg
    MockFix --> ResultAgg
    MockClean --> ResultAgg
    LocalRefactor --> ResultAgg
    LlamaModel --> ResultAgg
    
    %% Response Processing
    ResultAgg --> TaskLifecycle[ğŸ“ Task Lifecycle<br/>Event Logging]
    TaskLifecycle --> LogFiles[(ğŸ“„ JSON Logs)]
    
    ResultAgg --> ResponseFormat[ğŸ“¤ Response Formatter<br/>OpenAI Compatible]
    ResponseFormat --> StreamCheck{ğŸŒŠ Stream Response?}
    
    StreamCheck -->|Yes| StreamResponse[ğŸ“¡ Streaming Response<br/>Server-Sent Events]
    StreamCheck -->|No| JSONResponse[ğŸ“‹ JSON Response<br/>Standard Format]
    
    StreamResponse --> User
    JSONResponse --> User
    
    %% Error Flow
    ErrorHandler -->|Timeout| TimeoutResponse[â° Timeout Error<br/>30s Default]
    ErrorHandler -->|Retry Failed| RetryFailure[ğŸ”„ Retry Exhausted<br/>Exponential Backoff]
    ErrorHandler -->|Circuit Open| CircuitBreakerResponse[âš¡ Circuit Breaker<br/>Service Unavailable]
    
    TimeoutResponse --> User
    RetryFailure --> User
    CircuitBreakerResponse --> User
    
    %% Configuration Flow
    Config --> TaskKeywords[ğŸ·ï¸ Task Keywords<br/>Classification Rules]
    Config --> FunctionSigs[ğŸ“ Function Signatures<br/>Worker Contracts]
    Config --> EndpointMap[ğŸ—ºï¸ Endpoint Mapping<br/>Service URLs]
    
    %% Model Management
    MeshManager --> ModelInit[ğŸš€ Model Initialization<br/>Dependency Checking]
    ModelInit --> CheckLlama{ğŸ¦™ llama-cpp-python?}
    ModelInit --> CheckWolfram{ğŸ§® Wolfram Engine?}
    
    CheckLlama -->|Yes| LlamaReady[âœ… GGUF Ready]
    CheckLlama -->|No| LlamaFallback[âš ï¸ Fallback Mode]
    
    CheckWolfram -->|Yes| WolframReady[âœ… Wolfram Ready]
    CheckWolfram -->|No| WolframFallback[âš ï¸ Mock Responses]
    
    %% Microservice Architecture (Optional)
    MeshManager -.->|HTTP Mode| DebugEndpoint[ğŸŒ Debug Service<br/>:8001/debug]
    MeshManager -.->|HTTP Mode| AnalyzeEndpoint[ğŸŒ Analyze Service<br/>:8002/analyze]
    MeshManager -.->|HTTP Mode| FixEndpoint[ğŸŒ Fix Service<br/>:8003/fix]
    MeshManager -.->|HTTP Mode| CleanEndpoint[ğŸŒ Clean Service<br/>:8004/clean]
    
    %% External Dependencies
    WolframExec -.-> WolframEngine[ğŸ§® Wolfram Engine<br/>External Process]
    LlamaModel -.-> GGUFFiles[ğŸ“ GGUF Model Files<br/>Local Storage]
    AgentMemory -.-> ContextFiles[ğŸ“ Context JSONs<br/>File System]
    
    %% Styling
    classDef userInterface fill:#e1f5fe,stroke:#01579b,stroke-width:2px
    classDef apiLayer fill:#f3e5f5,stroke:#4a148c,stroke-width:2px
    classDef adminMesh fill:#e8f5e8,stroke:#2e7d32,stroke-width:2px
    classDef llmMesh fill:#fff3e0,stroke:#ef6c00,stroke-width:2px
    classDef workers fill:#fce4ec,stroke:#880e4f,stroke-width:2px
    classDef fallback fill:#fff8e1,stroke:#f57f17,stroke-width:2px
    classDef config fill:#f1f8e9,stroke:#558b2f,stroke-width:2px
    classDef external fill:#fafafa,stroke:#424242,stroke-width:2px
    
    class User,IDE,CLI userInterface
    class API,Health,Models,Chat apiLayer
    class Dispatcher,TaskParser,CouncilRouter,AttentionRouter,MemoryExpander,FunctionCourier,PayloadAssembly adminMesh
    class MeshManager,TaskRouter,ResultAgg,ResponseFormat llmMesh
    class DebugHandler,AnalyzeHandler,FixHandler,CleanHandler,RefactorHandler workers
    class MockDebug,MockAnalyze,MockFix,MockClean,FallbackCheck fallback
    class Config,TaskKeywords,FunctionSigs,EndpointMap config
    class WolframEngine,GGUFFiles,ContextFiles,LogFiles external
```

## Signal Flow Description

### 1. **Entry Points** 
- User interactions via REST API, VS Code Continue extension, or CLI
- All requests flow through FastAPI server on port 8000

### 2. **API Layer Processing**
- Request validation and error handling
- Health checks and model listing endpoints
- Main chat completions endpoint with retry logic

### 3. **Administrative Mesh** 
- **Task Classification**: Enhanced keyword-based parsing
- **Model Selection**: Council router chooses appropriate admin
- **Context Retrieval**: Attention router gets relevant memory
- **Signature Loading**: Function courier ensures contract compliance
- **Payload Assembly**: All data packaged for execution

### 4. **LLM Mesh Routing**
- Task router directs to appropriate worker handler
- Each task type has dedicated handler with fallback logic
- Supports both in-process and microservice deployment

### 5. **Worker Execution**
- **Debug/Analyze/Clean**: Wolfram Language workers (with fallbacks)
- **Fix**: PyTorch/GGUF models (with fallbacks) 
- **Refactor**: Local processing
- All workers have mock implementations for reliability

### 6. **Response Processing**
- Results aggregated and formatted
- OpenAI-compatible response structure
- Support for both streaming and standard responses
- Comprehensive error handling and logging

### 7. **Configuration System**
- Centralized keyword mappings and function signatures
- Easy extensibility for new task types
- Single source of truth for system behavior

### 8. **Fallback Strategy**
- Graceful degradation when external tools unavailable
- Circuit breaker prevents cascade failures
- Meaningful responses even in minimal environments

This architecture provides **robust, scalable, and maintainable** AI coding assistance with professional-grade reliability and clear upgrade paths for enhanced functionality.
